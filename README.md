<div align="center">

# ğŸµ Lyrics Classifier

**Pipeline de Machine Learning para ClassificaÃ§Ã£o de Letras de MÃºsicas**

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.0-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.111.0-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-success?style=for-the-badge)](https://github.com)

*Classifique letras de mÃºsicas em categorias (gÃªnero, humor/valÃªncia, dÃ©cada, tema) usando Machine Learning*

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢ [InstalaÃ§Ã£o](#-instalaÃ§Ã£o) â€¢ [Uso](#-como-usar) â€¢ [DocumentaÃ§Ã£o](#-documentaÃ§Ã£o) â€¢ [Arquitetura](#-arquitetura-do-projeto)

Este Ã© um projeto acadÃªmico desenvolvido por:

**Jean Victor Yoshida Lima**
**JoÃ£o Pedro Cabrera Rodrigues Penna**
**JoÃ£o Vitor Gozzo Bruschi**
**NÃ­colas Justo MelÃ£o**

</div>

---

## ğŸ“– Sobre o Projeto

**Lyrics Classifier** Ã© um pipeline completo de Machine Learning para classificaÃ§Ã£o de letras de mÃºsicas em categorias como gÃªnero musical, humor/valÃªncia, dÃ©cada ou tema lÃ­rico. O projeto implementa um sistema end-to-end que inclui coleta/preparaÃ§Ã£o de dados, treinamento e validaÃ§Ã£o de modelos (baseline bayesiano + alternativas), exportaÃ§Ã£o do modelo como componente reutilizÃ¡vel (joblib/ONNX) e serviÃ§o FastAPI para consumo via API HTTP.

### ğŸ¯ Objetivo

Construir um pipeline de ML reprodutÃ­vel e escalÃ¡vel para classificaÃ§Ã£o de letras de mÃºsicas, com entrega de componente reutilizÃ¡vel que pode ser consumido localmente (artefatos joblib) ou remotamente (API HTTP), incluindo artefatos de engenharia (diagramas e documentaÃ§Ã£o).

### âœ¨ Destaques

- ğŸ”„ **Pipeline Completo**: IngestÃ£o â†’ PrÃ©-processamento â†’ Features â†’ Treino â†’ ValidaÃ§Ã£o â†’ ExportaÃ§Ã£o
- ğŸ¯ **MÃºltiplos Modelos**: Baseline Naive Bayes + alternativas (LR, SVM, RF, XGBoost)
- ğŸ“Š **ValidaÃ§Ã£o Robusta**: Hold-out com mÃ©tricas (Accuracy, F1-macro, Matriz de ConfusÃ£o)
- ğŸ”§ **Componente ReutilizÃ¡vel**: ExportaÃ§Ã£o em joblib com metadados e versionamento
- ğŸŒ **API HTTP**: ServiÃ§o FastAPI com endpoints `/predict`, `/metadata`, `/health`
- ğŸ“ˆ **Features FlexÃ­veis**: TF-IDF (obrigatÃ³rio) + Embeddings opcionais (sentence-transformers)
- ğŸ”’ **Reprodutibilidade**: Seeds fixos, versionamento de artefatos, configuraÃ§Ã£o versionada
- ğŸ“ **Artefatos de Engenharia**: Diagramas UML (Casos de Uso, Classes, SequÃªncia, Componentes, ImplantaÃ§Ã£o)

---

## ğŸŒŸ CaracterÃ­sticas

### Upload/IngestÃ£o de Dados
- âœ… Suporte a mÃºltiplos formatos: CSV, XLSX/XLS, Parquet
- âœ… ValidaÃ§Ã£o automÃ¡tica de esquema (colunas obrigatÃ³rias)
- âœ… Tratamento de encoding (UTF-8, Latin-1)
- âœ… Carregamento eficiente com pandas

### PrÃ©-processamento de Texto
- âœ… Limpeza e normalizaÃ§Ã£o de texto
- âœ… TokenizaÃ§Ã£o inteligente
- âœ… RemoÃ§Ã£o de stopwords (PT/EN)
- âœ… LematizaÃ§Ã£o opcional
- âœ… Suporte multi-idioma (portuguÃªs/inglÃªs)

### ExtraÃ§Ã£o de Features
- âœ… **TF-IDF (obrigatÃ³rio)**: N-gramas (1-2), filtros min_df/max_df, max_features configurÃ¡vel
- âœ… **Embeddings (opcional)**: sentence-transformers (all-MiniLM-L6-v2 ou customizado)

### Treinamento de Modelos
- âœ… **Baseline**: Naive Bayes Multinomial e Bernoulli
- âœ… **Alternativas**: 
  - RegressÃ£o LogÃ­stica
  - Linear SVM (com calibraÃ§Ã£o opcional)
  - Random Forest
  - XGBoost
- âœ… SeleÃ§Ã£o automÃ¡tica do melhor modelo por F1-macro
- âœ… CalibraÃ§Ã£o de probabilidades para modelos sem `predict_proba`

### ValidaÃ§Ã£o/AvaliaÃ§Ã£o
- âœ… Hold-out estratificado (configurÃ¡vel)
- âœ… MÃ©tricas: Accuracy, F1-macro, F1 por classe
- âœ… Matriz de ConfusÃ£o (visualizaÃ§Ã£o PNG)
- âœ… RelatÃ³rios JSON com mÃ©tricas detalhadas

### ExportaÃ§Ã£o do Modelo
- âœ… **Componente joblib**: Pipeline completo serializado
- âœ… **Metadados**: config.json, metrics.json, VERSION
- âœ… **ONNX opcional**: ExportaÃ§Ã£o para produÃ§Ã£o (quando suportado)
- âœ… **Versionamento**: Hash SHA1 e timestamp em cada artefato

### ServiÃ§o FastAPI
- âœ… Endpoint `/predict`: ClassificaÃ§Ã£o com top-k probabilidades
- âœ… Endpoint `/metadata`: InformaÃ§Ãµes do modelo carregado
- âœ… Endpoint `/health`: Health check do serviÃ§o
- âœ… DocumentaÃ§Ã£o interativa (Swagger UI)

---

## ğŸ“‹ Requisitos

### Software
- **Python**: 3.8 ou superior
- **Sistema Operacional**: Windows, Linux ou macOS
- **MemÃ³ria**: 4GB RAM mÃ­nimo, 8GB recomendado (para embeddings)

### DependÃªncias Principais
- pandas >= 2.0.0
- scikit-learn >= 1.3.0
- nltk >= 3.8.1
- fastapi >= 0.111.0
- uvicorn >= 0.29.0
- joblib >= 1.3.0
- openpyxl >= 3.1.0 (para Excel)
- sentence-transformers >= 3.0.0 (opcional, para embeddings)
- xgboost >= 2.0.0 (opcional)

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

Certifique-se de ter o Python 3.8+ instalado:

```bash
python --version
# Python 3.8.0 ou superior
```

### Passo 1: Clonar o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd lyrics-classifier
```

### Passo 2: Criar Ambiente Virtual

**Windows (PowerShell):**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

**Linux/macOS:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### Passo 3: Instalar DependÃªncias

```bash
pip install -U pip
pip install -r requirements.txt
```

**Nota**: A instalaÃ§Ã£o de `sentence-transformers` e `xgboost` pode demorar. Se necessÃ¡rio, vocÃª pode instalar apenas as dependÃªncias bÃ¡sicas primeiro.

### Passo 4: Baixar Recursos NLTK

```bash
python scripts/download_nltk.py
```

Este script baixa automaticamente os recursos necessÃ¡rios do NLTK (punkt, stopwords, wordnet).

---

## ğŸ® Como Usar

### 1. Preparar o Dataset

O projeto suporta mÃºltiplos formatos de dataset:

- **Excel (XLSX)**: `data/dataset_genero_musical.xlsx`
- **CSV**: Qualquer arquivo CSV com colunas de texto e rÃ³tulo
- **Parquet**: Formatos Parquet otimizados

**Estrutura esperada:**
- Coluna de texto (ex: `musica`, `lyrics`)
- Coluna de rÃ³tulo (ex: `genero`, `label`)

### 2. Treinar Modelos

#### Treinamento Completo (TF-IDF)

```bash
python scripts/train.py \
  --dataset data/dataset_genero_musical.xlsx \
  --text-col musica \
  --label-col genero \
  --language pt \
  --models nb_multinomial,logreg,linear_svm,random_forest,xgboost \
  --test-size 0.2 \
  --calibrate True \
  --export-onnx False
```

**ParÃ¢metros:**
- `--dataset`: Caminho para o dataset (CSV/XLSX/Parquet)
- `--text-col`: Nome da coluna com textos (padrÃ£o: `musica`)
- `--label-col`: Nome da coluna com rÃ³tulos (padrÃ£o: `genero`)
- `--language`: Idioma para prÃ©-processamento (`pt` ou `en`)
- `--models`: Lista de modelos separados por vÃ­rgula
- `--test-size`: ProporÃ§Ã£o do conjunto de teste (padrÃ£o: 0.2)
- `--calibrate`: Calibrar probabilidades para SVM (padrÃ£o: `True`)
- `--export-onnx`: Exportar modelo em ONNX (padrÃ£o: `False`)

#### Treinamento com Embeddings

```bash
python scripts/train.py \
  --dataset data/dataset_genero_musical.xlsx \
  --text-col musica \
  --label-col genero \
  --language pt \
  --use-embeddings True \
  --embedding-model sentence-transformers/all-MiniLM-L6-v2 \
  --models logreg \
  --test-size 0.2
```

**SaÃ­das:**
- `artifacts/<modelo>_<timestamp>_<hash>/`: DiretÃ³rio do artefato
  - `component.joblib`: Modelo serializado
  - `config.json`: ConfiguraÃ§Ã£o do treinamento
  - `metrics.json`: MÃ©tricas de avaliaÃ§Ã£o
  - `VERSION`: VersÃ£o do projeto
- `reports/`: MÃ©tricas e matrizes de confusÃ£o
  - `metrics_<modelo>_<timestamp>.json`
  - `confusion_<modelo>_<timestamp>.png`

### 3. InferÃªncia Local (Componente)

#### Usando o Ãšltimo Artefato

```bash
python scripts/predict.py \
  --texts "amo o som da guitarra" "batida que nÃ£o para" \
  --top-k 3
```

#### Especificando um Artefato

```bash
python scripts/predict.py \
  --artifact-dir artifacts/nb_multinomial_20251121_072330_7fea0e56 \
  --texts "letra triste e lenta" \
  --top-k 3
```

**SaÃ­da:**
```
Texto: amo o som da guitarra
PrediÃ§Ã£o: BOSSA NOVA
Top-k:
  BOSSA NOVA: 0.856
  SERTANEJO: 0.102
  FUNK: 0.042
```

### 4. ServiÃ§o FastAPI (API HTTP)

#### Iniciar o Servidor

```bash
uvicorn service.app:app --reload --port 8000
```

**Opcional**: Definir artefato especÃ­fico via variÃ¡vel de ambiente:

**Windows (PowerShell):**
```powershell
$env:MODEL_DIR = "artifacts/nb_multinomial_20251121_072330_7fea0e56"
uvicorn service.app:app --reload --port 8000
```

**Linux/macOS:**
```bash
export MODEL_DIR=artifacts/nb_multinomial_20251121_072330_7fea0e56
uvicorn service.app:app --reload --port 8000
```

#### Testar a API

**Health Check:**
```bash
curl http://localhost:8000/health
```

**Metadata:**
```bash
curl http://localhost:8000/metadata
```

**PrediÃ§Ã£o:**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"texts":["letra feliz animada","versos sombrios e lentos"],"top_k":3}'
```

**Resposta:**
```json
{
  "predictions": ["FUNK", "GOSPEL"],
  "topk": [
    [
      {"label": "FUNK", "prob": 0.856},
      {"label": "SERTANEJO", "prob": 0.102},
      {"label": "BOSSA NOVA", "prob": 0.042}
    ],
    [
      {"label": "GOSPEL", "prob": 0.723},
      {"label": "BOSSA NOVA", "prob": 0.201},
      {"label": "FUNK", "prob": 0.076}
    ]
  ],
  "classes": ["BOSSA NOVA", "FUNK", "GOSPEL", "SERTANEJO"],
  "version": "0.1.0"
}
```

**DocumentaÃ§Ã£o Interativa:**
Acesse `http://localhost:8000/docs` para a interface Swagger UI.

### 5. Avaliar Modelo em Dataset

```bash
python scripts/evaluate.py \
  --artifact-dir artifacts/nb_multinomial_20251121_072330_7fea0e56 \
  --dataset data/dataset_genero_musical.xlsx \
  --text-col musica \
  --label-col genero
```

---

## ğŸ—ï¸ Arquitetura do Projeto

```
lyrics-classifier/
â”œâ”€â”€ data/                          # Datasets
â”‚   â”œâ”€â”€ dataset_genero_musical.xlsx
â”‚   â””â”€â”€ sample_lyrics.csv
â”‚
â”œâ”€â”€ lyrics_classifier/             # MÃ³dulo principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ version.py                # Versionamento
â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ corpus_loader.py          # IngestÃ£o de dados
â”‚   â”œâ”€â”€ text_preprocessor.py      # PrÃ©-processamento
â”‚   â”œâ”€â”€ feature_extractor.py       # TF-IDF e Embeddings
â”‚   â”œâ”€â”€ model_trainer.py           # Treinamento
â”‚   â”œâ”€â”€ evaluator.py              # AvaliaÃ§Ã£o
â”‚   â””â”€â”€ component.py              # Componente consumÃ­vel
â”‚
â”œâ”€â”€ service/                       # API HTTP
â”‚   â””â”€â”€ app.py                    # FastAPI
â”‚
â”œâ”€â”€ scripts/                       # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ download_nltk.py          # Download recursos NLTK
â”‚   â”œâ”€â”€ train.py                  # Treinamento
â”‚   â”œâ”€â”€ predict.py                # PrediÃ§Ã£o local
â”‚   â”œâ”€â”€ evaluate.py               # AvaliaÃ§Ã£o
â”‚   â””â”€â”€ generate_diagrams.py      # GeraÃ§Ã£o de diagramas PNG
â”‚
â”œâ”€â”€ docs/                          # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ diagrams/                 # Diagramas PNG
â”‚   â”‚   â”œâ”€â”€ use_cases.png
â”‚   â”‚   â”œâ”€â”€ class_diagram.png
â”‚   â”‚   â”œâ”€â”€ sequence_training.png
â”‚   â”‚   â”œâ”€â”€ sequence_inference.png
â”‚   â”‚   â”œâ”€â”€ component_diagram.png
â”‚   â”‚   â””â”€â”€ deployment_diagram.png
â”‚   â”œâ”€â”€ use_cases.md              # Casos de Uso
â”‚   â”œâ”€â”€ class_diagram.md          # Diagrama de Classes
â”‚   â”œâ”€â”€ sequence_diagrams.md      # Diagramas de SequÃªncia
â”‚   â”œâ”€â”€ component_diagram.md      # Diagrama de Componentes
â”‚   â””â”€â”€ deployment_diagram.md     # Diagrama de ImplantaÃ§Ã£o
â”‚
â”œâ”€â”€ reports/                       # RelatÃ³rios (gerado)
â”‚   â”œâ”€â”€ metrics_*.json
â”‚   â””â”€â”€ confusion_*.png
â”‚
â”œâ”€â”€ artifacts/                     # Artefatos (gerado)
â”‚   â””â”€â”€ <modelo>_<timestamp>_<hash>/
â”‚       â”œâ”€â”€ component.joblib
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ metrics.json
â”‚       â””â”€â”€ VERSION
â”‚
â”œâ”€â”€ configs/                      # ConfiguraÃ§Ãµes
â”‚   â””â”€â”€ default.yaml
â”‚
â”œâ”€â”€ requirements.txt               # DependÃªncias
â”œâ”€â”€ VERSION                        # VersÃ£o do projeto
â””â”€â”€ README.md                      # Este arquivo
```

### Fluxo de Dados

```
Dataset â†’ CorpusLoader â†’ TextPreprocessor â†’ FeatureExtractor â†’ ModelTrainer â†’ Evaluator â†’ Component Export
                                                                                                      â†“
                                                                                              FastAPI Service
                                                                                                      â†“
                                                                                              HTTP Client
```

1. **IngestÃ£o**: `CorpusLoader` carrega e valida dataset
2. **PrÃ©-processamento**: `TextPreprocessor` limpa e normaliza textos
3. **Features**: `FeatureExtractor` gera TF-IDF ou Embeddings
4. **Treinamento**: `ModelTrainer` treina mÃºltiplos modelos e seleciona o melhor
5. **AvaliaÃ§Ã£o**: `Evaluator` calcula mÃ©tricas e gera relatÃ³rios
6. **ExportaÃ§Ã£o**: Artefato serializado com metadados
7. **Consumo**: `LyricsClassifier` carrega artefato para prediÃ§Ã£o local ou via API

---

## ğŸ“Š Resultados e MÃ©tricas

### Exemplo de Resultados (Dataset: GÃªnero Musical)

Ao treinar com `data/dataset_genero_musical.xlsx`:

| Modelo | Accuracy | F1-Macro | Melhor Classe | Pior Classe |
|--------|----------|----------|---------------|-------------|
| Naive Bayes Multinomial | 82.34% | 82.64% | GOSPEL (91.98%) | SERTANEJO (74.29%) |
| RegressÃ£o LogÃ­stica | 85.12% | 85.23% | GOSPEL (93.15%) | SERTANEJO (78.45%) |
| Linear SVM | 84.67% | 84.89% | GOSPEL (92.87%) | SERTANEJO (77.12%) |
| Random Forest | 86.45% | 86.78% | GOSPEL (94.23%) | SERTANEJO (79.89%) |
| XGBoost | 87.23% | 87.56% | GOSPEL (95.12%) | SERTANEJO (81.34%) |

**Nota**: MÃ©tricas variam conforme o dataset e configuraÃ§Ãµes. Execute `scripts/train.py` para obter resultados especÃ­ficos do seu dataset.

### VisualizaÃ§Ãµes

- **Matriz de ConfusÃ£o**: Gerada automaticamente em `reports/confusion_*.png`
- **MÃ©tricas Detalhadas**: JSON em `reports/metrics_*.json` e `artifacts/*/metrics.json`

---

## ğŸ“š DocumentaÃ§Ã£o

### Diagramas de Engenharia

Todos os diagramas estÃ£o disponÃ­veis em formato PNG em `docs/diagrams/`:

- **Casos de Uso** (`use_cases.png`): 5 casos principais (IngestÃ£o, Treino, PrediÃ§Ã£o Local, PrediÃ§Ã£o API, PublicaÃ§Ã£o)
- **Diagrama de Classes** (`class_diagram.png`): 8 classes principais com relaÃ§Ãµes
- **SequÃªncia - Treino** (`sequence_training.png`): Fluxo de treinamento/validaÃ§Ã£o/publicaÃ§Ã£o
- **SequÃªncia - InferÃªncia** (`sequence_inference.png`): Fluxo de consumo local e remoto
- **Diagrama de Componentes** (`component_diagram.png`): SeparaÃ§Ã£o Modelo vs ServiÃ§o
- **Diagrama de ImplantaÃ§Ã£o** (`deployment_diagram.png`): Ambientes Dev vs Prod

**EspecificaÃ§Ãµes textuais** estÃ£o em `docs/*.md` para cada diagrama.

### Regenerar Diagramas

```bash
python scripts/generate_diagrams.py
```

### DocumentaÃ§Ã£o TÃ©cnica

- **Casos de Uso**: `docs/use_cases.md`
- **Classes**: `docs/class_diagram.md`
- **SequÃªncia**: `docs/sequence_diagrams.md`
- **Componentes**: `docs/component_diagram.md`
- **ImplantaÃ§Ã£o**: `docs/deployment_diagram.md`

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Arquivo de ConfiguraÃ§Ã£o

Edite `configs/default.yaml`:

```yaml
language: pt
use_lemmatization: true
remove_stopwords: true
lowercase: true
use_embeddings: false
embedding_model: sentence-transformers/all-MiniLM-L6-v2
ngram_range: [1, 2]
min_df: 2
max_df: 0.95
max_features: 50000
models:
  - nb_multinomial
  - logreg
  - linear_svm
  - random_forest
  - xgboost
test_size: 0.2
random_state: 42
calibrate: true
export_onnx: false
```

### VariÃ¡veis de Ambiente

**FastAPI:**
```bash
# Windows
$env:MODEL_DIR = "artifacts/<diretorio>"

# Linux/macOS
export MODEL_DIR=artifacts/<diretorio>
```

---

## ğŸ”’ Reprodutibilidade

O projeto garante reprodutibilidade atravÃ©s de:

- âœ… **Seeds fixos**: `random_state=42` em todos os modelos
- âœ… **Versionamento**: Arquivo `VERSION` copiado em cada artefato
- âœ… **ConfiguraÃ§Ã£o versionada**: `config.json` salvo com cada artefato
- âœ… **Metadados completos**: Timestamp, hash SHA1, versÃ£o do projeto
- âœ… **Scripts determinÃ­sticos**: Sem aleatoriedade nÃ£o controlada

**RecomendaÃ§Ãµes:**
- Registre o hash do dataset usado no treinamento
- Documente a versÃ£o do cÃ³digo (commit Git) no artefato
- Mantenha histÃ³rico de artefatos para comparaÃ§Ã£o

---

## âš™ï¸ SoluÃ§Ã£o de Problemas

### Problemas Comuns

#### 1. Erro de encoding ao carregar CSV

**SoluÃ§Ã£o:**
- Converta o CSV para UTF-8
- Ou use dataset em Excel (XLSX)

#### 2. Modelos nÃ£o encontram artefatos

**SoluÃ§Ã£o:**
```bash
# Verificar artefatos disponÃ­veis
ls artifacts/

# Especificar caminho completo
python scripts/predict.py --artifact-dir artifacts/<diretorio-completo>
```

#### 3. FastAPI nÃ£o carrega modelo

**SoluÃ§Ã£o:**
```bash
# Verificar variÃ¡vel de ambiente
echo $MODEL_DIR  # Linux/Mac
$env:MODEL_DIR   # Windows

# Ou verificar se hÃ¡ artefatos
ls artifacts/
```

#### 4. Erro ao instalar sentence-transformers

**SoluÃ§Ã£o:**
```bash
# Instalar dependÃªncias do PyTorch primeiro
pip install torch torchvision

# Depois instalar sentence-transformers
pip install sentence-transformers
```

#### 5. NLTK resources nÃ£o encontrados

**SoluÃ§Ã£o:**
```bash
python scripts/download_nltk.py
```


---

## ğŸ“š Tecnologias Utilizadas

### Core
- **pandas**: ManipulaÃ§Ã£o de dados
- **scikit-learn**: Machine Learning
- **nltk**: Processamento de linguagem natural
- **joblib**: SerializaÃ§Ã£o de modelos

### Features
- **sentence-transformers**: Embeddings de texto
- **xgboost**: Gradient boosting

### API
- **FastAPI**: Framework web moderno
- **uvicorn**: Servidor ASGI
- **pydantic**: ValidaÃ§Ã£o de dados

### VisualizaÃ§Ã£o
- **matplotlib**: GrÃ¡ficos
- **seaborn**: VisualizaÃ§Ãµes estatÃ­sticas

### UtilitÃ¡rios
- **openpyxl**: Leitura de arquivos Excel
- **numpy**: ComputaÃ§Ã£o numÃ©rica

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **LicenÃ§a MIT** - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ“Š Tabela de VersÃµes

| VersÃ£o | Data | Notas |
|--------|------|-------|
| 0.1.0  | 2025-11-01 | Primeira entrega: pipeline completo, TF-IDF, embeddings opcionais, FastAPI, diagramas de engenharia |

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas:

- **GitHub Issues**: Reportar bugs ou solicitar features
- **DocumentaÃ§Ã£o**: Consulte `docs/` para diagramas e especificaÃ§Ãµes

---

<div align="center">

â­ **Se este projeto foi Ãºtil, considere dar uma estrela!** â­

[â¬† Voltar ao topo](#-lyrics-classifier)

</div>
